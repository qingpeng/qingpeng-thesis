\chapter{Introduction}

\section{Overview} Species diversity is an important measurement of ecological
communities. Scientists believe that there is a relationship between species
diversity and ecosystem processes \cite{Loreau:2001aa}. Evaluating the species
diversity in a community is a central research topic in macroorganism ecology.
Many methods have been developed over the last few decades, aimed at answering
questions such as ``how many species of birds are in this habitat''.
Nevertheless, until recently scientists had not started to think seriously
about larger-scale questions such as ``How many species are there on earth?''
\cite{May:1988aa} or ``How many species are there in the ocean?''
\cite{Mora:2011aa} until recently. Why? The answer is straightforward:
Microorganisms represent the vast majority of the Earth's biodiversity and the
assessment of microbial diversity is quite difficult.

It is believed that microbial diversity is the outermost frontier of the
exploration of diversity \cite{magurran2011biological}. Microorganisms are
ubiquitous. There are more
bacterial cells in our body than human cells \cite{Savage:1977aa}. 
There are several reasons why assessment of microbial diversity is such a
challenge. First, the concept of species is ambiguous. Morphological
examination is impossible: fewer than 1\% of microorganisms  in the biosphere
cannot be cultivated by traditional cultivation
techniques\cite{Curtis:2002aa}. To overcome this obstacle, metagenomics has
emerged, driven by the progress of next-generation sequencing (NGS) technology.
Lots of metagenomics projects have been performed on samples ranging from acid
mine drainage channels to human gut. For complex environmental samples such as
soil, the resulting data sets can be huge. There are approximately a billion
microbial cells, with about 4 petabase pairs of DNA($4*{10}^{12}$ bp)
\cite{Zarraonaindia:2013aa}. Since we have limited sequencing power, the
resulting metagenomics data sets from highly complex samples (e.g. soil) only
correspond to a tiny fraction of the actual genomic content in the sample. The
large size of data sets and the low sequencing coverage make the assessment of
microbial diversity of high diversity sample even harder. Novel methods are
needed.


\section{Next-generation sequencing} Sequencing technology is changing quickly.
Over the past decade, next-generation sequencing (NGS) has become the dominant
technology and almost replaced classic Sanger sequencing technology. Illumina
and Roche 454 are the two most popular platforms. Illumina can generate reads
of shorter lengths, typically up to 150 base pairs(bp) for HiSeq and 250 bp for MiSeq
platform\cite{Qin:2010aa, Mason:2012aa}.   % @CTB up to 250 for MiSeq and 150 @QP edited
However, at a much lower cost compared to the Roche 454 sequencing
technology, which generates reads with a length of 500 to 1K bp.
Because of the advantage of
the low cost, there is a trend towards Illumina is dominating the sequencing
market, which means that while designing any tool for metagenomics, a developer
should take the relatively short length of Illumina reads into account.


\section{Metagenomics} 
It is believed that the word ``metagenomics'' was coined
in 1998 \cite{Handelsman:1998aa}; it can be translated as `beyond the genome'
\cite{Gilbert:2011aa}. At that time, it was based on the technique of cloning
environmental DNA randomly and screening for genes of interest, especially 16S
ribosomal RNA (rRNA) genes. This technique was firstly applied in practice by
Schmidt et al. in 1991 \cite{Schmidt:1991aa}. It was a crucial step in
expanding sequence-based investigation to the microbial world. Before that it
was standard protocol to culture and isolate microbes and do analysis. It
resulted in a much narrower picture of the diversity of an ecosystem as only a
small portion of the microbial species (5\% or less) in the biosphere can be
cultured with traditional cultivation techniques \cite{Sogin:2006aa}.
Metagenomics, with the concept of cloning DNA directly from sample 
without cultivation, brought researchers the ability to explore the entire
spectrum of organisms in an environment.

The number of microbial species in some ecological communities is huge. In soil,
it is estimated that there exist millions of species with most of them in low
abundance \cite{Gans:2005aa}. The improvement of NGS technology with ever higher throughput and ever lower
costs has been accelerating metagenomics research recently, % @CTB transition?@QP edited.
since only high throughput NGS strategy can sample the
contents of those populations deeply enough to examine rare species.

Currently, there are two approaches in metagenomics. One is amplicon
metagenomics, in which genes of interest, such as 16S rRNA genes, are amplified
and sequenced \cite{Sogin:2006aa}. This is the traditional way dating back to
the 1991 work by Schmidt et al. Many microbial diversity studies have relied on
this approach. The other approach is whole genome shotgun metagenomics, which
sequences randomly isolated DNA fragments without targeting specific genes.
Since the whole genomes of organisms in a sample are available, and not just
the limited genes of interest like 16S/18S rRNA, this whole genome shotgun
sequencing approach can in theory provide better taxonomic resolution and more
information benefiting other investigation \cite{Tyson:2004aa}
\cite{Qin:2010aa}.  Now there are thousands of metagenomic samples available in
online database, such as MG-RAST \cite{Glass:2010aa}.

There have been many metagenomics projects focusing on the microbial samples of
different kinds of habitat, from extreme environment such as acid mine drainage
channels with low complexity \cite{Tyson:2004aa}, and medium complexity samples
like human gut \cite{Qin:2010aa} and cow rumen \cite{Hess:2011aa}, to high
complexity samples like seawater \cite{Venter:2004aa} and soil
\cite{Gilbert:2010aa}.

Metagenomics studies have revealed lots of knowledge of the microbial community in
different habitats. Some of them shed light on the explanation of some serious
human diseases. Studies have shown associations between human gut metagenomes
and type II diabetes \cite{Qin:2012aa}, obesity \cite{Turnbaugh:2009aa,
Kau:2011aa} or Crohn's disease \cite{Morgan:2012aa}.

In almost all of these metagenomics projects, diversity analysis plays an
important role in supplying knowledge about the richness of species and the
abundance distribution of species in a sample or the similarity and difference
between samples, all of which are crucial to draw insightful and reliable
conclusions.




\section{Concept of diversity} When we characterize an ecological community,
diversity measurements are often the first step. It is always desirable to know
how many species there are in a sample -- its ``richness'' -- and how abundant
each species is relative to others in the same sample -- its ``evenness''. They
are straightforward conceptually. However, in practice, there are a large number of
quantities that are used to measure species diversity, for the many different
approaches to sampling individuals.

At a high level, three diversity indices are well established and used in
ecology; these are $\alpha$-diversity, $\beta$-diversity, and
$\gamma$-diversity. The $\alpha$-diversity is the diversity in one specific habitat
or sample. The $\beta$-diversity is the comparison of species diversity between habitats or
samples. The $\gamma$-diversity shows the total diversity of a region
with multiple ecosystems inside \cite{magurran2011biological}.

The concept of diversity has two aspects, richness and evenness. Richness is
the total number of species identified in a sample, which is the simplest
descriptor of a community structure. Evenness is a measure of how different the
abundance of a species is compared to other species in a community. If all the
species in a community has the same abundance, the community has a higher
evenness diversity. However, almost all natural communities are highly uneven,
which means the community is dominated by relatively few species and there are
a large number of species with low abundance. It raises a question about the
effectiveness of using the measurement of richness to represent species
diversity. Is a community with 1 dominant species and 10 rare species more
diverse than a community with 3 dominant species and 2 rare species? Thus, new
metrics taking both richness and evenness into account have been suggested. The two
most popular diversity indices are Shannon diversity
\cite{shannon2001mathematical}, which is based on information theory and shows
the information in a community as an estimate of diversity, and Simpson
diversity \cite{simpson1949measurement}, which basically shows the probability
that two individuals picked randomly from a community belong to the same
species.

Besides these two, Hill \cite{hill1973diversity} proposed a new diversity index
based on the species abundance distribution, which uses a weighted count of
species to measure diversity. It can be considered as a generalized diversity
index, since both Shannon and Simpson index and richness can be seen as special
cases of the Hill diversity index. It is necessary to note that we cannot tell
if any index is generically better than the others. It all depends on the
characteristics of a community and the process of sampling, as well as other
factors. How to choose the diversity indices to better represent the 
diversity information of a community has been investigated and discussed extensively 
\cite{Bohannan2003,Haegeman:2013aa,Morris2014}.

In microbial ecology, richness is simply the most popular index to measure
microbial diversity, partially because of the challenge raised by the different
characteristics of a microbial community. Most of the microbial diversity studies
concentrate on species richness comparison\cite{Bohannan2003}. 
Lots of methods to estimate richness in
classic ecology were borrowed to tackle the problem of estimating microbial
diversity, which will be discussed in the next section.
%@ ``most popular index'' - how did you assess this?
%@QP add citation
%%
\section{Problem statement}


In almost all  metagenomics projects, diversity analysis plays an important
role in supplying knowledge about the richness of species, the 
abundance distribution of species in a sample, and the similarity and difference between
different samples. The topic of microbial diversity measurement has been
investigated for a long time with many methods and software packages developed.
However, there still remains lots of room for more work.


Traditionally used for amplicon metagenomics data set, OTUs(Operational
Taxonomic Units) based on 16S rRNA genes are used as the basic units for
diversity analysis on shotgun metagenomic data. OTUs can be good replacements
of the concept of ``species'' in metagenomics. Basically contigs are assembled
from reads and are ``binned'' into OTUs using composition-based or
similarity-based approaches. Then the diversity can be estimated by using the
abundance information of the OTUs. The mainstream methods to measure microbial
diversity are still focusing on the use of 16S rRNA amplicon metagenomics data.
Many of the popular microbial diversity analysis software packages generally
accept 16S rRNA data as input. This is understandable because the concept of
OTU is from the similarity of 16S rRNA sequences. Using 16S rRNA data to
measure diversity is popular but is not without problems. The 16S rRNAs may not be
that reliable to be OTU markers. The reliability is sensitive to potential
horizontal gene transfer and the variance of gene copy in bacteria. There have
been suggestions that alternative marker genes should be used, such as single
copy housekeeping genes. Thus, measuring diversity beyond using 16S rRNA data is 
worth investigating.
% @CTB this last switch to 16s discussion is rather surprising...?
% @QP one more sentence is added.
% 
% from proposal, need to be rewritten to be more precise. @CTB yes ;)
Recently there are many more projects generating whole genome shotgun
metagenomics data sets. However, they are mainly used for assembly and
annotation purpose. Less attention was paid to diversity measurement using
these whole genome metagenomics data sets. One possible reason is that the
whole genome metagenomics data sets are often with low depth given the high
diversity of metagenomics samples compared to 16S rRNA ampicon metagenomics
data set. Assembly and annotation are always challenging with the low depth and
lack of reference sequences. It is also true for diversity measurement. On the
other hand, although with low depth, some whole genome metagenomics data sets
are of large size because of the high diversity. For instance, there may be 4
petabase pairs of DNA in a gram of soil \cite{Zarraonaindia:2013aa}. Many of
those methods for sequence binning or diversity estimation do not scale well
and will not work for large metagenomics data sets. For instance, many
composition-based binning approaches involve k-mer/signature frequency
distribution calculation, which is rather computationally expensive. Even basic
sequence alignment will be impossible for large metagenomics data sets. Many of
those statistical software packages to estimate diversity using various
estimators are not prepared for the large scale of whole genome metagenomics
data.

With the development of NGS technology, the cost of sequencing is dropping
rapidly. Whole genome metagenomics sequencing is more popular and a large amount
of metagenomics data is being generated with increasing speed, which cannot be
even met by the increase of computational capacity. Novel methods that can
scale well are extremely needed to deal with the increasingly large
metagenomics data set.


\section{Significance of research}

% @CTB I think this needs to be rewritten using language not copy/pasted from
% other papers.
% @QP done. has been rewritten

We established a series of approaches to enable scalable and effective
investigation of microbial diversity using whole-genome shotgun metagenomic
data. Firstly a k-mer counting package - khmer was developed to enable fast and
memory efficient k-mer-based analysis of sequencing data sets\cite{Zhang2014,khmer}. Khmer relies on 
Count-Min Sketch, a probabilistic data structure used to store the frequency of 
distinct elements efficiently. Unlike other data structures used for k-mer 
counting, such as hash tables, suffix arrays, and trie structure, the Count-Min
Sketch has significantly low memory usage for sparse data sets with trade-off 
with counting false positive. We conducted extensive analysis on the
performance of the counting algorithm and benchmark to compare the performance
of the khmer to other k-mer counting packages. The initial motivation of
developing khmer was to count the  k-mers in metagenomes for diversity
analysis. Now khmer has been widely used for many other purposes, from enabling
large scale de novo metagenome assembly  to sequencing error detection and
correction.

Based on the efficient k-mer counting package khmer, especially with the ability
to do online counting and retrieval entirely in memory, we developed digital
normalization\cite{Brown2012}, "a single-pass computational algorithm that systematizes
coverage in shotgun sequencing data sets, thereby decreasing sampling 
variation, discarding redundant data, and removing the majority of errors." 
Digital normalization can reduce the computational expense of downstream analysis
such as assembly dramatically because after the normalization of sampling variance,
redundant reads are discarded as well as the errors in 
them. The algorithm of digital
normalization has been used by many research groups to facilitate their
analysis and has been implemented in different tools like Trinity and 
Illumina's TruSeq pipeline. Like digital normalization, based on the same
approach to estimate sequencing depth without a reference assembly, a streaming
approach to analyze and trim sequencing errors in short reads datasets was
developed\cite{zhang2015crossing}. The approach offers a general framework for streaming sequence
analysis and could be used for error correction and variant calling. Moreover,
the approach can be applied generically to data sets with variable sequencing
coverage, such as metagenomes especially.

Further more, by integrating efficient k-mer counting and a novel de Bruijn
graph mapping method based on digital normalization we developed a novel
approach to allow for scalable diversity analysis of large, complex
metagenomes.  A novel concept - IGS (informative genomic segment) is proposed
to represent the unique information in a metagenomics data set. The IGSs can be
used as a complement of OTUs to be the cornerstone for diversity analysis of
whole shotgun metagenomics data sets. The abundance of IGSs in different
samples can be retrieved by mapping the reads to de Bruijn graphs. In this
procedure, not like many other microbial diversity analysis methods, assembly or
binning is not required any more. This method was evaluated on multiple
metagenomes from a variety of environments (e.g., human body part, seawater,
soil). Given the velocity in growth of sequencing data, this method is
promising for analyzing highly diverse samples with relatively low
computational requirements. Further, as the method does not depend on reference
genomes, it also provides opportunities to tackle the large amounts of unknown
``dark matter'' we find in metagenomic datasets.


\section{Outline of dissertation}

In this dissertation I will discuss in detail a series of approaches enabling
scalable and effective investigation of microbial diversity using whole-genome
shotgun metagenomic data. In chapter 2, I will do a brief review of relevant
literature about the challenges I face to enable diversity analysis of
metagenomic data. In chapter 3, I will describe a novel approach to count
k-mers efficiently and a scalable approach to retrieve the coverage of a read
in a data set based on efficient and online k-mer counting. In chapter 4, I
will  introduce the two applications of this approach, digital normalization to
reduce the redundancy of metagenomic reads dataset and a streaming method to
analyze sequencing error. Both are critically important to the improvement of
other metagenomic data analysis approaches, like assembly, error trimming or
contigs/reads binning. In chapter 5, I will discuss how I developed the concept
of IGS based on efficient k-mer counting and digital normalization. The effort
to increase the accuracy of IGS based method will be discussed and the
performance of the IGS method on simulated data sets and real data sets will be
demonstrated. I will give a summary about how the novel statistical framework
based on IGS makes a difference to the diversity analysis in current microbial
ecology research and some directions of future work will be discussed in the
last chapter.


